# -*- coding: utf-8 -*-
"""PALLADIUM_CAR_STREAMLIT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kiarUd3WqN6Eu6vhsaQO22k14l2Tufnv

#MODELO CATBOOST PARA STREAMLIT
"""

!pip install catboost

import pandas as pd
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle
import sklearn

df_r.to_csv('df_r_streamlit', index=False, encoding='utf-8')

dir_archivo_streamlit = '/content/df_r_streamlit'
df_r_streamlit = pd.read_csv(dir_archivo_streamlit)

df_r_streamlit.describe()

df_r_streamlit.info()

df_m = df_r_streamlit.loc[:,['ID_RESERVA','TOP_6_NAMES_HOTELS',
 'NOCHES_AGRUPADAS',
 'REGIMEN',
 'USO',
 'PAX',
 'CLIENTE',
 'REPETIDOR',
 'MONEDA',
 'SEGMENTOCREDITO',
 'ID_PAGO',
 'COMERCIALIZADORA',
 'CANCELACION',
 'LLEGADA_MES_ANYO',
 'SALIDA_MES_ANYO',
 'TARGET',
 'MES_TOMA',
 'MES_MOD',
 'MES_TTOO',
 'LEAD_TIME_GROUP',
 'PAISES_AGRUPADOS',
 'ORIGEN_CLIENTE',
 'TIPO_MULTIPLE',
 'VALUE_DOLARES',
 'PRECIO_MEDIO_NOCHE_DOLARES',
 'TIPO_AGRUPADO_CAT','TRANSOCEANICO']]
df_m.head()

df_catboost_streamlit = df_m.loc[:,['ID_RESERVA','TOP_6_NAMES_HOTELS',
 'CANCELACION',
 'LLEGADA_MES_ANYO',
 'SALIDA_MES_ANYO',
 'LEAD_TIME_GROUP',
 'PAISES_AGRUPADOS']]
df_catboost_streamlit.head()

df_catboost_streamlit.info()

df_catboost_streamlit= df_catboost_streamlit.dropna()
df_catboost_streamlit.isna().sum()

# Definir las características (X) y la variable objetivo (y)
X = df_catboost_streamlit.drop(columns=['CANCELACION','ID_RESERVA'], axis=1)
y = df_catboost_streamlit['CANCELACION']

# Definir las columnas categóricas
categorical_columns = ['TOP_6_NAMES_HOTELS', 'LLEGADA_MES_ANYO', 'SALIDA_MES_ANYO', 'LEAD_TIME_GROUP', 'PAISES_AGRUPADOS']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear el modelo CatBoostClassifier
model_streamlit = CatBoostClassifier(iterations=100, depth=8, cat_features=categorical_columns, verbose=0)

X_train.shape,X_test.shape,y_train.shape,y_test.shape

X_train.columns

X_test.columns

y_test[0:30]

X_test[0:30]

Test= X_test.copy()
Test["y_test"]= y_test

Test[0:30]

# Entrenar el modelo
model_streamlit.fit(X_train, y_train)

feature_importance_streamlit = model_streamlit.feature_importances_

model_streamlit.get_n_features_in ()

model_streamlit.feature_names_

df = pd.DataFrame(X_train.columns)

df["Importance"]= model_streamlit.get_feature_importance().tolist()
df.head(25)
df.rename({0:"feature"}, axis=1, inplace=True)
df.head(25)

model_streamlit.get_feature_importance().tolist()

num_streamlit_features_selected = df.loc[df.Importance>1.0,:]
num_streamlit_features_selected

num_streamlit_features_selected["feature"]

df_s= num_streamlit_features_selected.sort_values(by ='Importance', ascending=False)
df_s

X_test.iloc[0,:]

model_streamlit.predict(X_test.iloc[0,:]), model_streamlit.predict_proba(X_test.iloc[0,:])

model_streamlit.predict_proba(X_test.iloc[0,:])[1]

# Realizar predicciones en los datos de prueba
y_pred_streamlit = model_streamlit.predict(X_test)
y_pred_proba_streamlit = model_streamlit.predict_proba(X_test)
y_pred_train_stramlit= model_streamlit.predict(X_train)

# Calcular la precisión del modelo
accuracy = accuracy_score(y_test, y_pred_streamlit)
accuracy_entr = accuracy_score(y_train,y_pred_train_stramlit)
print(f'Precisión del modelo_test: {accuracy:.2f}')
print(f'Precisión del modelo_train: {accuracy:.2f}')

y_test[0:10]

model_streamlit.predict_proba(X_test)[0:10]

model_streamlit.predict_proba(X_test)[:, 1][0:10]

Test["predictions"]= y_pred_streamlit
Test[0:10]

Test["Prob_CANCELACION"]= model_streamlit.predict_proba(X_test)[:, 1]
Test.head()

Test["Prob_NO_CANCELACION"]= model_streamlit.predict_proba(X_test)[:, 0]
Test.head()

"""## GUARDAR MODELO EN DISCO CON PICKLE"""

# Guardo modelo en el disco

with open("palladium_model_catboost.pkl", 'wb') as archivo:
    pickle.dump(model_streamlit, archivo)

#cargo el modelo guardado en disco
with open("palladium_model_catboost.pkl", 'rb') as archivo:
  loaded_model = pickle.load(archivo)   #para cargar el modelo entrenado

prediccion = loaded_model.predict(X_test[0:50])
prediccion

prediccion_proba=loaded_model.predict_proba(X_test[0:50])
prediccion_proba

pip freeze > requirements.txt